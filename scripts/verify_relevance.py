
import json
import os
import time
import urllib.request
import urllib.parse
import http.client

# API ì„¤ì •
NAVER_CLIENT_ID = "Ug7csvlUDeTe1I72ehKQ"
NAVER_CLIENT_SECRET = "pqPjVw9kig"

def calculate_relevance_score(item, target_name, target_menu):
    score = 0
    title = item.get('title', '').replace('<b>', '').replace('</b>', '')
    snippet = item.get('description', '').replace('<b>', '').replace('</b>', '')
    link = item.get('link', '')
    
    # 1. ì´ë¦„ ë§¤ì¹­ (ê°€ì¥ ì¤‘ìš”)
    if target_name in title:
        score += 50
    elif target_name[:3] in title: # ì´ë¦„ ì¼ë¶€ ë§¤ì¹­
        score += 20
        
    # 2. ë©”ë‰´/ì„¤ëª… ë§¤ì¹­ (ì˜ë¯¸ë¡ ì  ê³ ì •)
    if target_menu and any(word in title or word in snippet for word in target_menu.split()):
        score += 30
        
    # 3. ì‹ ë¢° ë„ë©”ì¸ ê°€ì¤‘ì¹˜ ë° ì‡¼í•‘ ë„ë©”ì¸ íŒ¨ë„í‹°
    if "naver.com" in link or "kakao.com" in link or "tistory.com" in link:
        score += 20
    if "shop" in link and "phinf.naver.net" in link:
        score -= 80 # ì‡¼í•‘/ìƒí’ˆê¶Œ í…ìŠ¤íŠ¸ ì´ë¯¸ì§€ ê°•ë ¥ íŒ¨ë„í‹° (ASIA v2.1)
        
    # 4. ë¶€ì • í‚¤ì›Œë“œ ë° ì‹œê°ì  ì˜¤ì—¼ í•„í„°ë§ (ASIA v2)
    # 4-1. ìƒì—…ì  í‚¤ì›Œë“œ (ë¬´ê´€ìš© ë°°ì œ)
    commercial_words = ["ì¿ íŒ¡", "ì‡¼í•‘", "ë§ˆì¼“", "ìŠ¤ë§ˆíŠ¸ìŠ¤í† ì–´", "ë°°ë‹¬", "íƒë°°", "ì„ ë¬¼ì„¸íŠ¸", "í• ì¸", "ì´ë²¤íŠ¸"]
    if any(cw in title or cw in snippet for cw in commercial_words):
        score -= 100
        
    # 4-2. í¬ê´„ì /ì •ë³´ì„± í…ìŠ¤íŠ¸ (ì´ë¦„ì´ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ íŒ¨ë„í‹° ì™„í™”)
    generic_text = ["ë§›ì§‘ 5", "ë§›ì§‘ 7", "ë§›ì§‘ 10", "ê°€ë³¼ë§Œí•œê³³", "ë¦¬ìŠ¤íŠ¸", "ë² ìŠ¤íŠ¸", "ë­í‚¹", "ì •ë¦¬", "ëª¨ìŒ"]
    if any(gt in title for gt in generic_text):
        if target_name in title:
            score -= 20 # ì´ë¦„ê³¼ í•¨ê»˜ ìˆìœ¼ë©´ ì•½í•œ íŒ¨ë„í‹°
        else:
            score -= 80 # ì´ë¦„ ì—†ì´ ë¦¬ìŠ¤íŠ¸ë§Œ ìˆìœ¼ë©´ ê°•í•œ íŒ¨ë„í‹°
        
    # 4-3. ê¸°íƒ€ ë¶€ì • í‚¤ì›Œë“œ
    negative_words = ["í”„ë¡œí•„", "ì¸ë¬¼", "í’ê²½", "ì§€ë„", "ëŒ€ë¬¸", "ë‹¤ë¥¸ê°€ê²Œ", "ê´‘ê³ "]
    if any(nw in title for nw in negative_words):
        score -= 100
        
    # 5. í˜„ì¥ì„± ê°€ì¤‘ì¹˜ (ê°„íŒ, ì „ê²½, ë©”ë‰´íŒ ë“±)
    visual_anchor = ["ê°„íŒ", "ì „ê²½", "ì…êµ¬", "ë©”ë‰´íŒ", "ì°¨ë¦¼í‘œ", "ì‹ë‹¹", "ë…¸í¬"]
    if any(va in title for va in visual_anchor):
        score += 15
        
    return score

def get_verified_image(name, address_district, description, category):
    # ASIA ì•Œê³ ë¦¬ì¦˜: ì ì‘í˜• ì¿¼ë¦¬ ì „ëµ (Adaptive Querying Flow)
    
    # ì „ëµ 1: ì •ë°€ ì¿¼ë¦¬ (ì´ë¦„ + ì§€ì—­ + í•µì‹¬í‚¤ì›Œë“œ)
    keywords = description.split(':')[1].split(',')[0] if ':' in description else description[:10]
    queries = [
        f"{name} {address_district} {keywords} ëŒ€í‘œì‚¬ì§„",
        f"{name} {address_district} ë§›ì§‘ ìŒì‹",
        f"{name} {category} ëŒ€í‘œì´ë¯¸ì§€"
    ]
    
    best_overall_img = None
    max_overall_score = -1

    for i, q in enumerate(queries):
        encText = urllib.parse.quote(q)
        url = f"https://openapi.naver.com/v1/search/image?query={encText}&display=10&sort=sim"
        
        req = urllib.request.Request(url)
        req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
        req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
        
        try:
            res = urllib.request.urlopen(req)
            data = json.loads(res.read().decode('utf-8'))
            
            for item in data.get('items', []):
                score = calculate_relevance_score(item, name, description)
                
                # ì¿¼ë¦¬ ì°¨ìˆ˜ì— ë”°ë¥¸ íŒ¨ë„í‹° (ì •ë°€í• ìˆ˜ë¡ ê°€ì )
                score -= (i * 10) 
                
                # í•´ìƒë„ ì²´í¬
                try:
                    w, h = int(item.get('sizewidth', 0)), int(item.get('sizeheight', 0))
                    if w < 400 or h < 300: score -= 40
                    if w > 1000: score += 10 # ê³ í•´ìƒë„ ê°€ì 
                except: pass
                
                if score > max_overall_score:
                    max_overall_score = score
                    best_overall_img = item.get('link')
            
            # 1ì°¨ ì¿¼ë¦¬ì—ì„œ ì¶©ë¶„íˆ ë†’ì€ ì ìˆ˜(90+)ê°€ ë‚˜ì˜¤ë©´ ì¦‰ì‹œ ì¢…ë£Œ
            if max_overall_score >= 90:
                break
                
        except: continue
        
    return best_overall_img, max_overall_score

def run_iqrg_verification():
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    path = os.path.join(root_dir, 'src', 'data', 'places.json')
    
    with open(path, 'r', encoding='utf-8') as f:
        places = json.load(f)
    
    print(f"ğŸš€ [IQRG v3] ì •ë°€ ì´ë¯¸ì§€ ì •í™” ì‹œì‘ (ëŒ€ìƒ: {len(places)}ê°œ)")
    
    replaced_count = 0
    confirmed_count = 0
    low_confidence_count = 0
    
    for i, p in enumerate(places):
        print(f"  ğŸ” [{i+1}/{len(places)}] {p['name']} ë¶„ì„ ì¤‘...")
        
        # ASIA v2 (Adjusted) ì—”ì§„ìœ¼ë¡œ ìµœì  ì´ë¯¸ì§€ ê²€ìƒ‰
        new_img, score = get_verified_image(p['name'], p.get('addressCity', '') + " " + p.get('addressDistrict', ''), p['description'], p['category'])
        
        if new_img and score >= 85:
            if p['image_url'] != new_img:
                print(f"    âœ¨ ê³ í’ˆì§ˆ ì´ë¯¸ì§€ êµì²´ (Score: {score})")
                p['image_url'] = new_img
                replaced_count += 1
            else:
                print(f"    âœ… ê¸°ì¡´ ì´ë¯¸ì§€ ë¬´ê²°ì„± í™•ì¸ (Score: {score})")
                confirmed_count += 1
        elif new_img and score >= 60:
            print(f"    âš ï¸ ì¤‘ê°„ ì‹ ë¢°ë„ ì´ë¯¸ì§€ ê²€ì¶œ (Score: {score}) - ê¸°ì¡´ ìœ ì§€")
            confirmed_count += 1
        else:
            print(f"    â— ì €ì‹ ë¢° ì´ë¯¸ì§€ ì˜ì—­ (Best Score: {score}) - ì›ë³¸ ë³´ì¡´ ë° ê²€í†  ëŒ€ìƒ")
            low_confidence_count += 1
            
        time.sleep(0.1)

    with open(path, 'w', encoding='utf-8') as f:
        json.dump(places, f, ensure_ascii=False, indent=2)
    
    print(f"\nâœ… IQRG v3 ë¬´ê²°ì„± ë¦¬í¬íŠ¸")
    print(f"  - ë¬´ê²°ì„± í™•ì¸: {confirmed_count}ê°œ")
    print(f"  - ê³ í’ˆì§ˆ êµì²´: {replaced_count}ê°œ")
    print(f"  - ì €ì‹ ë¢°/ê²€í† í•„ìš”: {low_confidence_count}ê°œ")
    print(f"  - ì´ {len(places)}ê°œ ì—…ì²´ ì •ë³´ ë³´ì¡´ ì™„ë£Œ.")

if __name__ == "__main__":
    run_iqrg_verification()
