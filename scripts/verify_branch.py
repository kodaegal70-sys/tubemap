import json
import os
import time
import urllib.request
import urllib.parse

# .env.local í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
def load_env():
    env_path = os.path.join(os.path.dirname(os.path.dirname(os.path.abspath(__file__))), '.env.local')
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                if '=' in line and not line.startswith('#'):
                    key, value = line.strip().split('=', 1)
                    os.environ[key] = value

load_env()
NAVER_CLIENT_ID = os.environ.get("NAVER_CLIENT_ID")
NAVER_CLIENT_SECRET = os.environ.get("NAVER_CLIENT_SECRET")

def search_media_branch(name, media):
    """ë¯¸ë””ì–´ì™€ ì—…ì²´ëª…ì„ ì¡°í•©í•˜ì—¬ ì‹¤ì œ ë…¸ì¶œëœ ì§€ì ì„ ê²€ìƒ‰ ë¶„ì„"""
    query = f"{media} {name} ì§€ì  ìœ„ì¹˜"
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/blog?query={encText}&display=5"
    
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    
    try:
        res = urllib.request.urlopen(req)
        data = json.loads(res.read().decode('utf-8'))
        snippets = [item.get('description', '').replace('<b>', '').replace('</b>', '') for item in data.get('items', [])]
        titles = [item.get('title', '').replace('<b>', '').replace('</b>', '') for item in data.get('items', [])]
        combined_text = " ".join(titles + snippets)
        return combined_text
    except Exception as e:
        print(f"Error searching for {name}: {e}")
        return ""

def verify_mbv():
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    path = os.path.join(root_dir, 'src', 'data', 'places.json')
    
    with open(path, 'r', encoding='utf-8') as f:
        places = json.load(f)
    
    print(f"ğŸš€ [MBV Engine] ì§€ì  ì •ë°€ ê²€ì¦ ì‹œì‘ (ëŒ€ìƒ: {len(places)}ê°œ)")
    
    to_delete = []
    
    for p in places:
        # 1. ì§€ëª…/ì§€ì ëª…ì´ í¬í•¨ëœ ê²½ìš°ë§Œ ì •ë°€ ê²€ì¦ ëŒ€ìƒìœ¼ë¡œ ì¶”ì¶œ
        if any(word in p['name'] for word in ["ë³¸ì ", "ì ", "ì•ˆì‚°", "ì²œì•ˆ", "ì„œìš¸"]):
            print(f"  ğŸ” ë¶„ì„ ì¤‘: {p['name']} ({p['media']})")
            
            # ë¯¸ë””ì–´ ë…¸ì¶œ í…ìŠ¤íŠ¸ ë¶„ì„
            context = search_media_branch(p['name'], p['media'])
            
            if not context:
                print(f"    âš ï¸ [íŒŒì•… ë¶ˆê°€] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ -> ë°°ì œ ëŒ€ìƒ")
                to_delete.append(p['id'])
                continue
            
            # ì£¼ì†Œ ì •ë³´ (ë™/êµ¬) ì¶”ì¶œ
            addr = p.get('address', '')
            district = p.get('addressDistrict', '')
            
            # ì»¨í…ìŠ¤íŠ¸ì— í˜„ì¬ ì£¼ì†Œ í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
            found_match = False
            if district and district in context:
                found_match = True
            
            # 'ë³¸ì ' í‚¤ì›Œë“œ ë§¤ì¹­ í™•ì¸
            if "ë³¸ì " in p['name'] and "ë³¸ì " in context:
                found_match = True
            
            if found_match:
                print(f"    âœ… [ê²€ì¦ ì„±ê³µ] ë¯¸ë””ì–´ ë…¸ì¶œ ìœ„ì¹˜ ì¼ì¹˜ í™•ì¸")
            else:
                # íŒŒì•…ì´ ì•ˆ ë˜ê±°ë‚˜ ì£¼ì†Œê°€ ë‹¤ë¥¸ ê²½ìš°
                print(f"    âŒ [ê²€ì¦ ì‹¤íŒ¨/íŒŒì•… ë¶ˆê°€] ì¼ì¹˜ ì •ë³´ ë¯¸ê²€ì¶œ -> ë°°ì œ ëŒ€ìƒ")
                to_delete.append(p['id'])
                
            time.sleep(0.1) # API ì†ë„ ì¡°ì ˆ

    # ìµœì¢… ê²°ê³¼ ë³´ê³  ë° ì‚­ì œ ì‹¤í–‰
    print(f"\nğŸ—‘ï¸ [MBV ê²°ê³¼] ì´ {len(to_delete)}ê°œ í•­ëª© ë°°ì œ ê²°ì •")
    new_places = [p for p in places if p['id'] not in to_delete]
    
    # ì‘ì—… ì „ ë°±ì—…
    with open(path + '.bak', 'w', encoding='utf-8') as f:
        json.dump(places, f, ensure_ascii=False, indent=2)

    with open(path, 'w', encoding='utf-8') as f:
        json.dump(new_places, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… ë°ì´í„° ì •ë¦¬ ì™„ë£Œ! (ì”ì—¬ ë°ì´í„°: {len(new_places)}ê°œ)")
    return to_delete

if __name__ == "__main__":
    verify_mbv()
