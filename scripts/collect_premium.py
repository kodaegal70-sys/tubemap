
import requests
import json
import time
import os
import urllib.request
import urllib.parse
from typing import List, Dict

# API ì„¤ì •
KAKAO_API_KEY = "c6088c2c7ec5f0e1ed1122ba613db0fb"
NAVER_CLIENT_ID = "Ug7csvlUDeTe1I72ehKQ"
NAVER_CLIENT_SECRET = "pqPjVw9kig"

# ì •ì œí•  ì¹´í…Œê³ ë¦¬ (ì œì™¸ ëŒ€ìƒ)
EXCLUDE_CATEGORIES = ["ìŠˆí¼ë§ˆì¼“", "ëŒ€í˜•ë§ˆíŠ¸", "ì§€í•˜ì² ì—­", "ê¸°ì°¨ì—­", "ì˜¨ì²œ", "ëª©ìš•íƒ•", "ì‚¬ìš°ë‚˜", "ìœ ì ì§€", "ê´€ê´‘", "ì „ì‹œ", "ë°•ë¬¼ê´€", "ì²´í—˜", "ë¶€ì§€", "ì‹í’ˆíŒë§¤"]

def get_kakao_category_search(category_code: str, region: str = "ì•„ì‚°"):
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    results = []
    # ì•„ì‚° ì§€ì—­ì˜ ì—¬ëŸ¬ ì§€ì ì—ì„œ ê²€ìƒ‰í•˜ì—¬ ë²”ìœ„ë¥¼ ë„“í˜
    search_points = ["ì•„ì‚°ì‹œì²­", "ì˜¨ì–‘ì˜¨ì²œì—­", "ì²œì•ˆì•„ì‚°ì—­", "ì‹ ì •í˜¸", "ê³µì„¸ë¦¬ì„±ë‹¹", "ìˆœì²œí–¥ëŒ€í•™êµ", "í˜„ì¶©ì‚¬", "íƒ•ì •ë©´", "ë°°ë°©ì—­"]
    
    for point in search_points:
        for page in range(1, 4):
            params = {"query": f"{point} ë§›ì§‘", "page": page, "size": 15, "category_group_code": category_code}
            try:
                res = requests.get(url, headers=headers, params=params)
                data = res.json()
                if not data['documents']: break
                for doc in data['documents']:
                    if "ì•„ì‚°" not in doc['address_name']: continue
                    results.append({
                        "name": doc['place_name'],
                        "lat": float(doc['y']), "lng": float(doc['x']),
                        "address": doc['address_name'], "phone": doc.get('phone', ''),
                        "category": doc.get('category_name', '').split('>')[-1].strip(),
                        "road_address": doc.get('road_address_name', '')
                    })
                time.sleep(0.1)
            except: break
    return results

def verify(name: str):
    # ë¯¸ë””ì–´ ê²€ì¦
    encText = urllib.parse.quote(f"ì•„ì‚° {name} ë°©ì†¡ ì¶œì—° ìœ íŠœë¸Œ")
    url = f"https://openapi.naver.com/v1/search/blog?query={encText}&display=15"
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID); req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    
    media = []
    description = ""
    try:
        res = urllib.request.urlopen(req)
        data = json.loads(res.read().decode('utf-8'))
        full_text = " ".join([i['title'] + i['description'] for i in data['items']]).replace('<b>', '').replace('</b>', '')
        
        # ë¯¸ë””ì–´ í‚¤ì›Œë“œ ì²´í¬
        if "ë°±ë°˜ê¸°í–‰" in full_text or "í—ˆì˜ë§Œ" in full_text: media.append("ì‹ê° í—ˆì˜ë§Œì˜ ë°±ë°˜ê¸°í–‰")
        if "ìƒí™œì˜ ë‹¬ì¸" in full_text or "ìƒí™œì˜ë‹¬ì¸" in full_text: media.append("ìƒí™œì˜ ë‹¬ì¸")
        if "ë§›ìˆëŠ”ë…€ì„ë“¤" in full_text or "ë§›ìˆëŠ” ë…€ì„ë“¤" in full_text: media.append("ë§›ìˆëŠ” ë…€ì„ë“¤")
        if "ìƒìƒì •ë³´" in full_text: media.append("ìƒìƒì •ë³´")
        if "ì¯”ì–‘" in full_text: media.append("ì¯”ì–‘ (ìœ íŠœë¸Œ)")
        if "í’ì" in full_text or "ë˜ê°„ì§‘" in full_text: media.append("í’ì ë˜ê°„ì§‘")
        if "íˆë°¥" in full_text: media.append("íˆë°¥ (ìœ íŠœë¸Œ)")
        if "6ì‹œ ë‚´ê³ í–¥" in full_text: media.append("6ì‹œ ë‚´ê³ í–¥")
        
        # ëŒ€í‘œ ë©”ë‰´ ì¶”ì¶œ (ë‹¨ìˆœ í…œí”Œë¦¿ ëŒ€ì²´)
        if "íƒ•ìˆ˜ìœ¡" in full_text: description = "ë°”ì‚­í•œ íƒ•ìˆ˜ìœ¡ê³¼ ê¹Šì€ ë§›ì˜ ì§¬ë½•ì´ ìœ ëª…í•œ ì•„ì‚° ë§›ì§‘"
        elif "ë°€ë©´" in full_text: description = "ì‹œì›í•˜ê³  ë‹´ë°±í•œ ìœ¡ìˆ˜ê°€ ì¼í’ˆì¸ 70ë…„ ì „í†µì˜ ë°€ë©´ ë…¸í¬"
        elif "ì¹¼êµ­ìˆ˜" in full_text: description = "ì«„ê¹ƒí•œ ì†ë©´ë°œê³¼ ì‹œì›í•œ êµ­ë¬¼ì´ ì–´ìš°ëŸ¬ì§„ ì¹¼êµ­ìˆ˜ ì „ë¬¸ì "
        elif "ìŒˆë°¥" in full_text: description = "ì‹ ì„ í•œ ìŒˆì±„ì†Œì™€ ì •ê°ˆí•œ ë°‘ë°˜ì°¬ì´ ë‹ë³´ì´ëŠ” ìš°ë ìŒˆë°¥ ëª…ì†Œ"
        elif "ìˆœëŒ€" in full_text: description = "ì¡ë‚´ ì—†ì´ êµ¬ìˆ˜í•œ ìˆœëŒ€êµ­ê³¼ ì«„ê¹ƒí•œ ë¨¸ë¦¿ê³ ê¸° ì „ë¬¸ì "
        elif media: description = f"{media[0]} ì†Œê°œ í›„ ë” ìœ ëª…í•´ì§„ ì•„ì‚°ì˜ ìˆ¨ì€ ë§›ì§‘"
        else: description = "ì•„ì‚° ì§€ì—­ í˜„ì§€ì¸ë“¤ì´ ì•„ë¼ëŠ” ì •ì„± ê°€ë“í•œ ë§›ì§‘"

    except: pass
    
    if not media: return None, None, None
    
    # ì´ë¯¸ì§€
    encTextImg = urllib.parse.quote(f"ì•„ì‚° {name} ëŒ€í‘œì´ë¯¸ì§€")
    urlImg = f"https://openapi.naver.com/v1/search/image?query={encTextImg}&display=1"
    reqImg = urllib.request.Request(urlImg)
    reqImg.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID); reqImg.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    img_url = None
    try:
        resImg = urllib.request.urlopen(reqImg)
        dataImg = json.loads(resImg.read().decode('utf-8'))
        if dataImg['items']: img_url = dataImg['items'][0]['link']
    except: pass
    
    return "|".join(list(set(media))), img_url, description

def finalize():
    print("ğŸš€ [ìµœì¢… ìˆ˜ì§‘ ë° ì •ì œ] ì‹œì‘")
    final_places = []
    seen_keys = set()
    
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    
    # ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì¤‘ë³µ ë°©ì§€ìš©)
    src_path = os.path.join(root_dir, 'src', 'data', 'places.json')
    if os.path.exists(src_path):
        with open(src_path, 'r', encoding='utf-8') as f:
            for p in json.load(f):
                seen_keys.add(f"{p['name']}_{p['address']}")

    # 1. ì•„ì‚° ì§€ì—­ ê´‘ë²”ìœ„ ìŒì‹ì  í›„ë³´ ìˆ˜ì§‘
    print("ğŸ“ 1ë‹¨ê³„: ì•„ì‚° ì§€ì—­ ìŒì‹ì  í›„ë³´(500+) ìˆ˜ì§‘ ì¤‘...")
    candidates = get_kakao_category_search("FD6")
    candidates.extend(get_kakao_category_search("CE7")) # ì¹´í˜ í¬í•¨
    
    # 2. ê²€ì¦ ë° 100ê°œ ì„ ë³„
    print(f"ğŸ“ 2ë‹¨ê³„: í›„ë³´êµ°({len(candidates)}ê°œ) ê²€ì¦ ë° 100ê°œ ì„ ë³„ ì¤‘...")
    for c in candidates:
        if len(final_places) >= 100: break
        
        key = f"{c['name']}_{c['address']}"
        if key in seen_keys: continue
        if c['category'] in EXCLUDE_CATEGORIES: continue
        if "ë§ˆíŠ¸" in c['name'] or "ì " in c['name'] and len(c['name']) > 10: continue # í”„ëœì°¨ì´ì¦ˆ ê°„ì ‘ ê±°ë¥´ê¸°
        
        media, img, desc = verify(c['name'])
        if media and img:
            new_p = {
                "id": 2000 + len(final_places),
                "name": c['name'], "lat": c['lat'], "lng": c['lng'],
                "media": media, "description": desc,
                "address": c['address'], "phone": c['phone'], "image_url": img,
                "naver_url": f"https://map.naver.com/p/search/{urllib.parse.quote(c['name'])}",
                "category": c['category'], "addressProvince": "ì¶©ë‚¨", "addressCity": "ì•„ì‚°ì‹œ",
                "addressDistrict": c['road_address'].split(' ')[2] if len(c['road_address'].split(' ')) > 2 else ""
            }
            final_places.append(new_p)
            seen_keys.add(key)
            print(f"  âœ¨ [{len(final_places)}/100] {c['name']} ({media})")
            time.sleep(0.2)

    if final_places:
        output_path = os.path.join(root_dir, 'scripts', 'asan_premium_final.json')
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(final_places, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ‰ ìµœì¢… {len(final_places)}ê°œ ê³ í’ˆì§ˆ ë°ì´í„° ì €ì¥ ì™„ë£Œ: {output_path}")
    else:
        print("\nâŒ ê²€ì¦ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    finalize()
