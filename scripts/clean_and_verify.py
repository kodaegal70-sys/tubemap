#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ì´ˆê³ ì† & ë¬´ê²°ì„± ë¦¬ë·° ìˆ˜ì§‘ ì—”ì§„ (v6.0)
- YouTube ëŒ“ê¸€ + Google Places ë¦¬ë·° ë©€í‹° ìˆ˜ì§‘
- ë¦¬ë·° ë¯¸ë°œêµ´ ì‹œ ì¦‰ì‹œ ì‚­ì œ (Strict Filtering)
"""

import os
import json
import re
import requests
import concurrent.futures
from typing import Dict, List, Optional

def load_env():
    env_path = os.path.join(os.path.dirname(__file__), '..', '.env.local')
    env_vars = {}
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key] = value
    except: pass
    return env_vars

env = load_env()
YOUTUBE_API_KEY = env.get('YOUTUBE_API_KEY')
KAKAO_API_KEY = env.get('KAKAO_REST_API_KEY')
GOOGLE_API_KEY = env.get('GOOGLE_PLACES_API_KEY')

def get_google_data(store_name: str, address: str):
    """Google Placesì—ì„œ ì‚¬ì§„ê³¼ ë¦¬ë·° ë™ì‹œ ìˆ˜ì§‘"""
    url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
    params = {'input': f"{store_name} {address}", 'inputtype': 'textquery', 'fields': 'place_id,photos', 'key': GOOGLE_API_KEY}
    
    try:
        res = requests.get(url, params=params, timeout=5).json()
        if res.get('status') == 'OK' and res.get('candidates'):
            place_id = res['candidates'][0]['place_id']
            
            # ìƒì„¸ ì •ë³´(ë¦¬ë·°) ìˆ˜ì§‘
            detail_url = "https://maps.googleapis.com/maps/api/place/details/json"
            detail_params = {'place_id': place_id, 'fields': 'reviews,photos', 'language': 'ko', 'key': GOOGLE_API_KEY}
            detail = requests.get(detail_url, params=detail_params, timeout=5).json()
            
            result = detail.get('result', {})
            photo_url = None
            if result.get('photos'):
                ref = result['photos'][0]['photo_reference']
                photo_url = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={ref}&key={GOOGLE_API_KEY}"
            
            # ë¦¬ë·° ì¶”ì¶œ
            google_review = None
            if result.get('reviews'):
                # 20ìž ì´ìƒ 100ìž ì´í•˜ì˜ í•œêµ­ì–´ ë¦¬ë·° ì„ ë³„
                for r in result['reviews']:
                    text = r.get('text', '')
                    if len(text) > 20 and re.search(r'[ê°€-íž£]', text):
                        google_review = text.replace('\n', ' ').strip()
                        break
            
            return photo_url, google_review
    except: pass
    return None, None

def get_youtube_review(video_id: str, store_name: str, category: str) -> Optional[str]:
    url = "https://www.googleapis.com/youtube/v3/commentThreads"
    params = {'part': 'snippet', 'videoId': video_id, 'order': 'relevance', 'maxResults': 30, 'key': YOUTUBE_API_KEY}
    try:
        res = requests.get(url, params=params, timeout=5).json()
        if 'items' in res:
            for item in res['items']:
                comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
                comment = re.sub(r'<[^>]+>', '', comment)
                if 15 < len(comment) <= 100 and any(kw in comment for kw in [store_name[:2], 'ë§›', 'ì¶”ì²œ']):
                    return re.sub(r'[^\w\sê°€-íž£.,!?~]', '', comment).strip()
    except: pass
    return None

def process_and_clean():
    path = 'src/data/places.json'
    with open(path, 'r', encoding='utf-8') as f:
        places = json.load(f)
    
    clean_places = []
    print(f"ðŸ§¹ ë°ì´í„° ì •ì œ ì‹œìž‘ (ëŒ€ìƒ: {len(places)}ê°œ)")
    
    for p in places:
        print(f"[{p['name']}] ê²€ì¦ ì¤‘...")
        
        # 1. YouTube ë¦¬ë·° ì‹œë„
        yt_review = get_youtube_review(p['source_video_url'].split('v=')[-1], p['name'], p['category'])
        
        # 2. Google ë¦¬ë·° ì‹œë„ (YouTube ì‹¤íŒ¨ ì‹œ)
        g_photo, g_review = get_google_data(p['name'], p['address'])
        
        # ìµœì¢… ë¦¬ë·° ê²°ì •
        final_review = yt_review if yt_review else g_review
        
        if final_review:
            p['description'] = final_review
            p['image_url'] = g_photo if g_photo else p['image_url']
            clean_places.append(p)
            print(f"  âœ… ë¦¬ë·° í™•ë³´: {final_review[:30]}...")
        else:
            print(f"  âŒ ë¦¬ë·° ì—†ìŒ: ì‚­ì œ ëŒ€ìƒ")
            
    # ID ìž¬ì •ë ¬
    for i, p in enumerate(clean_places):
        p['id'] = i + 1
        
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(clean_places, f, ensure_ascii=False, indent=2)
    
    print(f"âœ¨ ì •ì œ ì™„ë£Œ: {len(places)} -> {len(clean_places)}ê°œ")

if __name__ == "__main__":
    process_and_clean()
