import json
import urllib.request
import urllib.parse
import os
import time

NAVER_CLIENT_ID = "Ug7csvlUDeTe1I72ehKQ"
NAVER_CLIENT_SECRET = "pqPjVw9kig"

BAD_DOMAINS = ["shopping", "smartstore", "coupang", "11st", "gmarket", "auction", "tmon", "shop.phinf"]
BAD_KEYWORDS_IN_TITLE = ["ë°€í‚¤íŠ¸", "í¬ì¥", "íƒë°°", "ê³µêµ¬", "íŒë§¤", "ì¶œì‹œ", "ìŠ¤í† ì–´", "ê²Œì„", "ì´ë²¤íŠ¸", "ì¦ì •", "í…€ë¸”ëŸ¬", "ê´‘ê³ ", "ë‹¤ìš´ë¡œë“œ", "ì‚¬ì „ì˜ˆì•½"]

TARGETS = {
    "ê³ ë„ì‹ ì ì‹¤ì ": ["ê³ ë„ì‹ ì ì‹¤ ì•Œë“±ì‹¬", "ê³ ë„ì‹ ì ì‹¤ ê³ ê¸°ì§‘"],
    "ë¸Œë¤¼ì…€í”„ë¼ì´": ["ë¸Œë¤¼ì…€í”„ë¼ì´ ê²½ì£¼ ê°ìíŠ€ê¹€", "ë¸Œë¤¼ì…€í”„ë¼ì´ í™©ë¦¬ë‹¨ê¸¸ ë¨¹ê±°ë¦¬"]
}

def search_strict(query):
    encText = urllib.parse.quote(query)
    # Using 'sim' to ensure relevance to strict query
    url = f"https://openapi.naver.com/v1/search/image?query={encText}&display=10&sort=sim&filter=medium"
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    try:
        response = urllib.request.urlopen(req)
        if response.getcode() == 200:
            data = json.loads(response.read().decode('utf-8'))
            for item in data['items']:
                link = item['link']
                title = item['title']
                if any(bd in link for bd in BAD_DOMAINS): continue
                if any(bk in title for bk in BAD_KEYWORDS_IN_TITLE): continue
                # Additional heuristic: Prefer blog images
                if "blog" in link or "post" in link:
                    return link
            # Fallback: if no blog image, take first non-bad one
            for item in data['items']:
                link = item['link']
                title = item['title']
                if any(bd in link for bd in BAD_DOMAINS): continue
                if any(bk in title for bk in BAD_KEYWORDS_IN_TITLE): continue
                return link
    except: pass
    return None

def main():
    print("ğŸš€ [Phase 43] íŠ¹ì • ì—…ì²´(ê³ ë„ì‹, ë¸Œë¤¼ì…€í”„ë¼ì´) ì´ë¯¸ì§€ ì´ˆì •ë°€ êµì²´")
    
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    src_path = os.path.join(root_dir, 'src', 'data', 'places.json')
    
    with open(src_path, 'r', encoding='utf-8') as f:
        places = json.load(f)
        
    updated = False
    for p in places:
        if p['name'] in TARGETS:
            queries = TARGETS[p['name']]
            new_img = None
            for q in queries:
                new_img = search_strict(q)
                if new_img: 
                    print(f"  âœ¨ Found strict image for {p['name']} with query '{q}'")
                    break
            
            if new_img and new_img != p.get('image_url'):
                p['image_url'] = new_img
                updated = True
                print(f"  âœ… Replaced Image for {p['name']}")
            elif not new_img:
                 print(f"  âŒ Failed to find clean image for {p['name']}")

    if updated:
        with open(src_path, 'w', encoding='utf-8') as f:
            json.dump(places, f, ensure_ascii=False, indent=2)
        print("\nğŸ’¾ Changes saved.")
    else:
        print("\nNo changes made.")

if __name__ == "__main__":
    main()
