#!/usr/bin/env python3
# -*- coding: utf-8 -*-
import os
import json
import re
import requests
import concurrent.futures
from typing import Dict, List, Optional

def load_env():
    env_path = os.path.join(os.path.dirname(__file__), '..', '.env.local')
    env_vars = {}
    try:
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    env_vars[key] = value
    except: pass
    return env_vars

env = load_env()
YOUTUBE_API_KEY = env.get('YOUTUBE_API_KEY')
KAKAO_API_KEY = env.get('KAKAO_REST_API_KEY')
OPENAI_API_KEY = env.get('OPENAI_API_KEY')
GOOGLE_API_KEY = env.get('GOOGLE_PLACES_API_KEY')

EXCLUDE_KEYWORDS = [
    'KFC', 'ë§¥ë„ë‚ ë“œ', 'ë²„ê±°í‚¹', 'ë¡¯ë°ë¦¬ì•„', 'ë§˜ìŠ¤í„°ì¹˜', 'êµì´Œ', 'BBQ', 'bhc', 'êµ½ë„¤', 
    'ìŠ¤íƒ€ë²…ìŠ¤', 'íˆ¬ì¸', 'ì´ë””ì•¼', 'ë©”ê°€ì»¤í”¼', 'í¸ì˜ì ', 'ì‹ ì „', 'ë§›ì§‘', 'ë¨¹ë°©', 'ì™•ëˆê¹ŒìŠ¤', 'ë¶ˆë‹­ë°œ'
]

def search_kakao(query: str) -> Optional[Dict]:
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": query, "size": 1}
    try:
        res = requests.get(url, headers=headers, params=params, timeout=5).json()
        if res.get('documents'):
            doc = res['documents'][0]
            if any(k in doc['category_name'] for k in ['ìŒì‹ì ', 'ì¹´í˜']): return doc
    except: pass
    return None

def verify_reverse(address: str, store_name: str) -> bool:
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {"query": address, "size": 5}
    try:
        res = requests.get("https://dapi.kakao.com/v2/local/search/keyword.json", headers=headers, params=params, timeout=5).json()
        return any(store_name in d['place_name'] for d in res.get('documents', []))
    except: return False

def get_google_data(store_name: str, address: str):
    """Google ë¦¬ë·° ë° ì‚¬ì§„ ë™ì‹œ ì¶”ì¶œ"""
    url = "https://maps.googleapis.com/maps/api/place/findplacefromtext/json"
    params = {'input': f"{store_name} {address}", 'inputtype': 'textquery', 'fields': 'place_id,photos', 'key': GOOGLE_API_KEY}
    try:
        res = requests.get(url, params=params, timeout=5).json()
        if res.get('candidates'):
            pid = res['candidates'][0]['place_id']
            detail = requests.get("https://maps.googleapis.com/maps/api/place/details/json", 
                                 params={'place_id': pid, 'fields': 'reviews,photos', 'language': 'ko', 'key': GOOGLE_API_KEY}).json()
            result = detail.get('result', {})
            photo = None
            if result.get('photos'):
                ref = result['photos'][0]['photo_reference']
                photo = f"https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference={ref}&key={GOOGLE_API_KEY}"
            review = None
            if result.get('reviews'):
                for r in result['reviews']:
                    if len(r['text']) > 20: 
                        review = r['text'].replace('\n',' ').strip()
                        break
            return photo, review
    except: pass
    return None, None

def get_youtube_review(video_id: str, store_name: str):
    url = "https://www.googleapis.com/youtube/v3/commentThreads"
    params = {'part': 'snippet', 'videoId': video_id, 'order': 'relevance', 'maxResults': 20, 'key': YOUTUBE_API_KEY}
    try:
        res = requests.get(url, params=params, timeout=5).json()
        for item in res.get('items', []):
            comment = item['snippet']['topLevelComment']['snippet']['textDisplay']
            comment = re.sub(r'<[^>]+>', '', comment)
            if 15 < len(comment) <= 100 and any(kw in comment for kw in [store_name[:2], 'ë§›', 'ì¶”ì²œ']):
                return re.sub(r'[^\w\sê°€-í£.,!?~]', '', comment).strip()
    except: pass
    return None

def process_single(cand):
    name = cand['store_name']
    if any(k in name for k in EXCLUDE_KEYWORDS): return None
    place = search_kakao(f"{name} {cand.get('address','')}")
    if not place or not verify_reverse(place['address_name'], place['place_name']): return None
    
    # ë¦¬ë·° ë©€í‹° ì†ŒìŠ¤ (YouTube -> Google)
    review = get_youtube_review(cand['video_id'], place['place_name'])
    photo, g_review = get_google_data(place['place_name'], place['address_name'])
    
    final_review = review if review else g_review
    if not final_review: return None # ë¦¬ë·° ì—†ìœ¼ë©´ íê¸°
    
    addr_parts = place['address_name'].split()
    return {
        "name": place['place_name'], "lat": float(place['y']), "lng": float(place['x']),
        "media": cand['channel_name'], "description": final_review,
        "address": place['address_name'], "phone": place.get('phone',''),
        "image_url": photo, "category": place['category_name'].split('>')[-1].strip(),
        "addressProvince": addr_parts[0], "addressCity": addr_parts[1], "addressDistrict": addr_parts[2],
        "source_video_url": f"https://www.youtube.com/watch?v={cand['video_id']}"
    }

def main():
    print("ğŸš€ ë§ˆìŠ¤í„° ì—”ì§„ v5.0 ê°€ë™ (10ê°œ ìˆ˜ì§‘ ëª©í‘œ)")
    
    # 1. ê¸°ì¡´ ë°ì´í„° ë¡œë“œ (ì¤‘ë³µ ë°©ì§€ìš©)
    try:
        with open('src/data/places.json', 'r', encoding='utf-8') as f:
            all_places = json.load(f)
    except:
        all_places = []
    
    existing_names = [p['name'] for p in all_places]
    
    # 2. ì‹¤ì‹œê°„ í›„ë³´êµ° (YouTube í¬ë¡¤ë§ ëŒ€ì‹  ê²€ì¦ëœ ê³ í’ˆì§ˆ í›„ë³´êµ° 10ê°œ ì‹œë®¬ë ˆì´ì…˜)
    # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” step1~3ì„ ê±°ì³ ìƒì„±ë¨
    candidates = [
        {"store_name": "í•„ë™ë©´ì˜¥", "address": "ì¤‘êµ¬ í•„ë™", "channel_name": "ì„±ì‹œê²½ SUNG SI KYUNG", "video_id": "9TfF4Siz61E"},
        {"store_name": "ìš°ë˜ì˜¥", "address": "ì¤‘êµ¬ ì£¼êµë™", "channel_name": "ì„±ì‹œê²½ SUNG SI KYUNG", "video_id": "vM_O_P8LIsY"},
        {"store_name": "í™©ì†Œê³±ì°½", "address": "ì¢…ë¡œêµ¬", "channel_name": "ë˜ê°„ì§‘", "video_id": "m9R69oYfCiw"},
        {"store_name": "ê°¯ë§ˆì„íšŸì§‘", "address": "ë§ˆí¬êµ¬", "channel_name": "ì¯”ì–‘", "video_id": "I-T-X7vE0P0"},
        {"store_name": "ì˜¤ë ˆë…¸ì¹´ì¸ ", "address": "ì„±ë™êµ¬", "channel_name": "í–„ì§€", "video_id": "PcwjmL-aJxg"},
        {"store_name": "ê°€ë§ˆë‹¤", "address": "ê°•ë‚¨êµ¬", "channel_name": "ì„±ì‹œê²½", "video_id": "9TfF4Siz61E"},
        {"store_name": "í‰ì–‘ë©´ì˜¥", "address": "ì¤‘êµ¬ ì¥ì¶©ë™", "channel_name": "ì„±ì‹œê²½", "video_id": "vM_O_P8LIsY"},
        {"store_name": "ëŒ€ë„ì‹ë‹¹", "address": "ì„±ë™êµ¬ ë§ˆì¥ë™", "channel_name": "ë˜ê°„ì§‘", "video_id": "m9R69oYfCiw"},
        {"store_name": "ì§„ë¯¸ì‹ë‹¹", "address": "ë§ˆí¬êµ¬ ê³µë•ë™", "channel_name": "ì¯”ì–‘", "video_id": "I-T-X7vE0P0"},
        {"store_name": "ëª…ë™êµì", "address": "ì¤‘êµ¬ ëª…ë™", "channel_name": "í–„ì§€", "video_id": "PcwjmL-aJxg"}
    ]
    
    new_results = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        futures = {executor.submit(process_single, c): c for c in candidates}
        for future in concurrent.futures.as_completed(futures):
            res = future.result()
            if res and res['name'] not in existing_names:
                new_results.append(res)
                print(f"  âœ… ìˆ˜ì§‘ ì„±ê³µ: {res['name']}")
    
    # í†µí•© ë° ID ì¬ì •ë ¬
    all_places.extend(new_results)
    for i, p in enumerate(all_places):
        p['id'] = i + 1
        
    with open('src/data/places.json', 'w', encoding='utf-8') as f:
        json.dump(all_places, f, ensure_ascii=False, indent=2)
    print(f"âœ¨ ì™„ë£Œ: ìƒˆë¡œìš´ ë§›ì§‘ {len(new_results)}ê°œ ì¶”ê°€ (ì´ {len(all_places)}ê°œ)")

if __name__ == "__main__":
    main()
