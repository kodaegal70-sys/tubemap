import json
import urllib.request
import urllib.parse
import os
import time

# API Keys
NAVER_CLIENT_ID = "Ug7csvlUDeTe1I72ehKQ"
NAVER_CLIENT_SECRET = "pqPjVw9kig"

BAD_DOMAINS = ["shopping", "smartstore", "coupang", "11st", "gmarket", "auction", "wemakeprice", "tmon", "shop.phinf"]
BAD_KEYWORDS_IN_TITLE = ["ë°€í‚¤íŠ¸", "í¬ìž¥", "íƒë°°", "ê³µêµ¬", "íŒë§¤", "ì¶œì‹œ", "ìŠ¤í† ì–´"]

def validate_and_replace_image(place):
    name = place['name']
    menu = place.get('category', 'ë§›ì§‘') # Use category or description hint
    
    # Check current image
    curr_url = place.get('image_url', '')
    if any(bd in curr_url for bd in BAD_DOMAINS):
        print(f"  âš ï¸ [Ad Detected] {name}: URL({curr_url}) contains shopping domain.")
    
    # Re-search with strict query
    # Query: "{Name} {Menu} ë°©ë¬¸ -ë°€í‚¤íŠ¸ -íƒë°°"
    query = f"{name} {menu} ë°©ë¬¸í›„ê¸° -ë°€í‚¤íŠ¸ -íƒë°° -í¬ìž¥"
    
    encText = urllib.parse.quote(query)
    url = f"https://openapi.naver.com/v1/search/image?query={encText}&display=3&sort=sim&filter=medium"
    
    req = urllib.request.Request(url)
    req.add_header("X-Naver-Client-Id", NAVER_CLIENT_ID)
    req.add_header("X-Naver-Client-Secret", NAVER_CLIENT_SECRET)
    
    try:
        response = urllib.request.urlopen(req)
        if response.getcode() == 200:
            data = json.loads(response.read().decode('utf-8'))
            for item in data['items']:
                link = item['link']
                title = item['title']
                
                # Check Bad Domains
                if any(bd in link for bd in BAD_DOMAINS): continue
                # Check Bad Title Keywords
                if any(bk in title for bk in BAD_KEYWORDS_IN_TITLE): continue
                
                # If pass, return this High Quality Image
                return link
    except Exception as e:
        print(f"  Error searching for {name}: {e}")
        
    return None

def main():
    print("ðŸš€ [Phase 42] ì´ë¯¸ì§€ í’ˆì§ˆ(ë°˜-ë°€í‚¤íŠ¸) ë¬´ê²°ì„± ìž¬ê²€ì¦ ì‹œìž‘")
    
    root_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    src_path = os.path.join(root_dir, 'src', 'data', 'places.json')
    
    with open(src_path, 'r', encoding='utf-8') as f:
        places = json.load(f)
        
    valid_places = []
    ids = 1
    
    for p in places:
        new_img = validate_and_replace_image(p)
        if new_img:
            if new_img != p.get('image_url'):
                print(f"  âœ¨ [Updated] {p['name']}: ì´ë¯¸ì§€ êµì²´ ì™„ë£Œ")
            p['image_url'] = new_img
            p['id'] = ids
            valid_places.append(p)
            ids += 1
        else:
            print(f"  âŒ [Deleted] {p['name']}: ìˆœìˆ˜ ë°©ë¬¸ê¸° ì´ë¯¸ì§€ í™•ë³´ ì‹¤íŒ¨ (Zero Tolerance)")
            
    # Save
    with open(src_path, 'w', encoding='utf-8') as f:
        json.dump(valid_places, f, ensure_ascii=False, indent=2)
        
    print(f"\nâœ… ê²€ì¦ ì™„ë£Œ. ì´ {len(places)} -> {len(valid_places)}ê°œ ìœ ì§€.")

if __name__ == "__main__":
    main()
